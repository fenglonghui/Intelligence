### 加载一个pdf文件内容后, 写提示词并交由大模型生成覆盖各个场景的问题

    下面给出一份“从 0 到 1”可落地的实现清单，按“拆任务 → 选工具 → 写 Prompt → 跑流程 → 后处理”五步展开。你既可以直接抄作业，也可以按需裁剪

    一、拆任务：到底要“什么样的问题”
        1.覆盖维度
          ‑ 事实型（What/Who/When/Where）
          ‑ 因果型（Why）
          ‑ 过程型（How）
          ‑ 假设/反事实（What if…）
          ‑ 评价型（Pros & Cons / 最佳实践）
        2.场景粒度
          ‑ 教学：课后测验、考试、面试
          ‑ 客服：FAQ、故障排查
          ‑ 合规：审计、风险评估
          ‑ 研究：文献综述、假设生成
        3.难度分级
          ‑ L1 回忆、L2 理解、L3 应用、L4 分析、L5 评价、L6 创造（Bloom）

  二、选工具：PDF→结构化文本→LLM
        1.解析层（任选）
          ‑ Python: PyMuPDF / pdfplumber → 保留坐标、表格
          ‑ Node: pdf-parse → 纯文本
          ‑ 云 API: Azure Document Intelligence / AWS Textract → 表格、KV 对
       
        2.切片层
          ‑ 按“页/段落/标题”三级树形保存，给每块加 chunk_id 与 heading_path
          ‑ 示例：
          ```
              chunk_id: 3.2.1  
              heading_path: 3 深度学习 → 3.2 反向传播 → 3.2.1 链式法则  
              text: “链式法则指出……”
          ```

        3.LLM 层
          ‑ 任意大模型（GPT-4 / Kimi / Qwen / Claude）
          ‑ 建议 temperature=0.7，top_p=0.95，输出 JSON 方便后续自动化

  三、写 Prompt：一套“元提示”即可通杀
     下面模板已内置“维度+场景+难度+格式”四个变量，运行时动态替换即可。

     ```
          你是一位“问题生成专家”。  
          任务：根据下方 PDF 原文片段，生成 {scene} 场景下的 {level} 难度问题，覆盖 {dimension} 维度。  
          
          要求：  
          1. 必须严格依据原文，禁止引入外部知识。  
          2. 每个问题后紧跟“参考答案”与“出处（chunk_id）”。  
          3. 输出合法 JSON 数组，字段：  
             {  
               "question": "问题文本",  
               "type": "<事实|因果|过程|假设|评价>",  
               "difficulty": "<L1-L6>",  
               "answer": "参考答案",  
               "chunk_id": "3.2.1"  
             }  
          4. 若原文为图表/代码，优先生成“看图/看代码作答”类问题。  
          5. 一次生成 {num} 题，不重复。  
          
          原文片段：  
          {text}
      
     ```

      调用示例（Python 伪代码）
      prompt_template = open("prompt_meta.txt").read()
      for chunk in chunks:
          prompt = prompt_template.format(
              scene="教学测验",
              level="L3",
              dimension="因果+过程",
              num=5,
              text=chunk.text
          )
          resp = llm.chat(prompt)
          qs = json.loads(resp)
          save_to_db(qs)

  四、跑流程：完整 Pipeline（单机版）
      1. 准备  
         pip install pymupdf openai tqdm pandas
      
      2. 解析  
         python pdf2chunks.py --input manual.pdf --output chunks.jsonl  
         # 字段: {"chunk_id":"1.1","heading_path":"1 简介","text":"xxx"}
      
      3. 生成  
         python bulk_qgen.py --model gpt-4 --prompt prompt_meta.txt \
              --chunks chunks.jsonl --scene 客服FAQ --level L2 \
              --dimension 事实+过程 --num 3 --output questions.jsonl
      
      4. 后处理  
         python dedup.py questions.jsonl > final.jsonl   # 相似题去重
         python export2csv.py final.jsonl > qa_bank.csv  # 给业务人员审阅


