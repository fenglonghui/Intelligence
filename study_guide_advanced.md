### 学习导读高级指引

#### 1.模型平台, 1.modelscope 平台, 2.Huggingface 平台

#### 2.提示词工程
       对于智能强的模型, 模型会按照提示词格式严格输出内容, 对于模型能力一般货比较弱的模型, 提示词格式几乎是失效!!!

#### 3.数据分割技术
       1.数据拆分类型:
          1.按固定长度分割
          2.语义分割
          3.按业务需求分割    (推荐)

       2.智能文档解析技术
          使用Mineru做文档转换,转换为markdown文件, 然后线下对markdown文件进行人工处理 (推荐) 
              https://mineru.net/
          使用 deepseek-ocr 处理复杂的多模态的pdf文档

#### 4.RAG知识库-数据结构化处理
       按业务需求对数据进行分割整理

#### 5.DeepSeek OCR工具(企业级vLLM本地部署)及Mineru工具数据解析
       用于数据文档解析

#### 6.Llama_indexRAG进阶_文档切分与重排序
       基于RAG初次排序基础之上, 对数据进行重排序(rerank)以提高精度、准确率

       使用重排序模型, 将top_k检索结果的语义score明显的分割开来: 使得语义相近的score分数特别相大, 语义不相关的score分数特别小, 即分割界限极大明显, 以此提高检索精度

#### 7.多场景多领域RAG知识隔离架构
       多个知识库统一调用管里架构
      
#### 8.大模型微调 
       目标: 基于现有的私有数据, 微调可以让模型具备处理该数据的功能
       微调落地场景: 
           1.模型固有的信息变换
           2.对话风格 
           3.针对专业问答系统的问题理解不到位时, 会使用微调技术帮助模型更好的理解用户的问题

       微调的分类:
           1.全量微调, (相当于预训练)
           2.增量微调, (冻结模型已有参数, 增加微调网络结构进行微调, 比如: 基于BERT模型的自定义微调训练, 用来进行分类)
           3.局部微调 (比如: RAG微调)

#### 9.自定义微调训练BERT模型效果测试

#### 10.GPT2中文生成模型定制化微调训练

#### 11.大模型本地化部署
       1. Ollama 服务, 适用于本地私优化部署使用
       2. vLLM 服务,    高并发性能突出, 商业上推荐它
       3. LMDeploy 服务,  速度快, 更加适合国产设备

#### 12.大模型微调-LLama Factor微调Qwen

#### 13.Ollama部署微调大模型

#### 14.LLamaFactory 模型导出量化

#### 15.vLLM自定义对话模板

#### 16.LLamaFactory与Xtuner分布式微调大模型

#### 17.大模型压缩训练（知识蒸馏）
        该技术不属于微调范畴, 适用于大模型初创研发领域

#### 18.大模型微调项目实战-数据工程篇

#### 19.大模型微调项目实战-训练与部署

#### 20.大模型评估测试 OpenCompass

#### 21.大模型分布式推理与量化部署

#### 22.多模态大模型应用

#### 23.RAG+微调实现智能专家系统（方案数据篇）

#### 24.RAG+微调实现智能专家系统（部署测试）
